{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classifier Analysis\n",
    "#### Word Count, Word Presence, TF-IDF, Bi-Gram, Wang - Manning, LSA, GloVe, % of training data \n",
    "\n",
    "Raj Sundhar Ravichandran, CS 533, Spring 2018.\n",
    "\n",
    "This notebook helps to analyse various Machine Learning classification algorithms with different features on both similar and different documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import itertools\n",
    "import vocabulary\n",
    "import newsreader\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "    \n",
    "vocab_file, vocab_file_type = \"20news-bydate-vocab.pkl\", \"pickle\"\n",
    "\n",
    "embedding_file, embedding_dimensions, embedding_cache = \\\n",
    "    \"glove6B50/glove.6B.50d.txt\", 50, \"20news-bydate-embedding.npz\"\n",
    "\n",
    "all_data, train_dir, dev_dir, test_dir = \\\n",
    "    \"20-news-bydate\", \"20-news-bydate/20news-bydate-train/\", None, \"20-news-bydate/20news-bydate-test/\"\n",
    "\n",
    "has_bad_metadata = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary and Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140907 words were not in glove\n"
     ]
    }
   ],
   "source": [
    "made_vocabulary = False\n",
    "if made_vocabulary :\n",
    "    v = vocabulary.Vocabulary.load(vocab_file, file_type=vocab_file_type)\n",
    "else: \n",
    "    tokens = newsreader.all_textfile_tokens(all_data, strip_metadata=has_bad_metadata)                                            \n",
    "    v = vocabulary.Vocabulary.from_iterable(tokens, file_type=vocab_file_type)\n",
    "    v.save(vocab_file)\n",
    "v.stop_growth()\n",
    "\n",
    "made_embedding = False\n",
    "if made_embedding :\n",
    "    e = newsreader.load_sparse_csr(embedding_cache)\n",
    "else: \n",
    "    e = newsreader.build_sparse_embedding(v, embedding_file, embedding_dimensions)\n",
    "    newsreader.save_sparse_csr(embedding_cache, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Types to make comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class1, class2 = \"rec.sport.hockey\", \"comp.windows.x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = []\n",
    "def selected(name) :\n",
    "    if not targets:\n",
    "        return True\n",
    "    if any(t.startswith(name) for t in targets) :\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build DataManager with Number of Counts for Each Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def use_default_features(vocab) :\n",
    "    return lambda data: vocab\n",
    "\n",
    "def count_features(features, gen_tokens) :\n",
    "    for t in gen_tokens :\n",
    "        r = features.add(t)\n",
    "        if r :\n",
    "            yield r    \n",
    "            \n",
    "count_data = newsreader.DataManager(train_dir + class1,\n",
    "                                       train_dir + class2,\n",
    "                                       test_dir + class1,\n",
    "                                       test_dir + class2,\n",
    "                                       use_default_features(v),\n",
    "                                       count_features,\n",
    "                                       dev_dir + class1 if dev_dir else None,\n",
    "                                       dev_dir + class2 if dev_dir else None,\n",
    "                                       strip_metadata=has_bad_metadata)\n",
    "\n",
    "count_data.initialize(build_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build DataManager with Presence/Absence (0/1) for each Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_boolean_features(feature_counter) :\n",
    "    def collect_features(features, gen_tokens) :\n",
    "        seen = set()\n",
    "        for f in feature_counter(features, gen_tokens) :\n",
    "            seen.add(f)\n",
    "        for f in seen :\n",
    "            yield f\n",
    "    return collect_features\n",
    "\n",
    "boolean_data = newsreader.DataManager(train_dir + class1,\n",
    "                                         train_dir + class2,\n",
    "                                         test_dir + class1,\n",
    "                                         test_dir + class2,\n",
    "                                         use_default_features(v),\n",
    "                                         make_boolean_features(count_features),\n",
    "                                         dev_dir + class1 if dev_dir else None,\n",
    "                                         dev_dir + class2 if dev_dir else None,\n",
    "                                         strip_metadata=has_bad_metadata)\n",
    "\n",
    "boolean_data.initialize(build_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to set up Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Experiment(object) :\n",
    "    '''Organize the process of getting data, building a classifier,\n",
    "    and exploring new representations'''\n",
    "    \n",
    "    def __init__(self, data, comment, classifier, cdesc) :\n",
    "        'set up the problem of learning a classifier from a data manager'\n",
    "        self.data = data\n",
    "        self.comment = comment\n",
    "        self.classifier = classifier\n",
    "        self.cdesc = cdesc\n",
    "        self.initialized = False\n",
    "        \n",
    "    def initialize(self) :\n",
    "        'materialize the training data, dev data and test data as matrices'\n",
    "        if not self.initialized :\n",
    "            self.train_X, self.train_y = self.data.training_data()\n",
    "            self.dev_X, self.dev_y = self.data.dev_data()\n",
    "            self.test_X, self.test_y = self.data.test_data()\n",
    "            self.initialized = True\n",
    "        \n",
    "    def fit_and_validate(self, report=True) :\n",
    "        'train the classifier and assess predictions on dev data'\n",
    "        if not self.initialized :\n",
    "            self.initialize()\n",
    "        self.classifier.fit(self.train_X, self.train_y)\n",
    "        self.dev_predictions = self.classifier.predict(self.dev_X)\n",
    "        self.accuracy = sklearn.metrics.accuracy_score(self.dev_y, self.dev_predictions)\n",
    "        if report :\n",
    "            print(\"{}\\nclassified by {}\\naccuracy {}\".format(self.comment, self.cdesc, self.accuracy))\n",
    "            \n",
    "    def xval(self, folds=20, report=True) :\n",
    "        accuracies = []\n",
    "        for i in range(folds) :\n",
    "            self.fit_and_validate(report=False)\n",
    "            accuracies.append(self.accuracy)\n",
    "        if report :\n",
    "            msg = \"{}\\nclassified by {}\\naverage accuracy {} (std {})\"\n",
    "            print(msg.format(self.comment, self.cdesc, \n",
    "                             sum(accuracies)/folds,\n",
    "                             np.std(accuracies)))\n",
    "    \n",
    "    @classmethod\n",
    "    def transform(cls, expt, operation, description, classifier, cdesc) :\n",
    "        'use operation to transform the data from expt and set up new classifier'\n",
    "        if not expt.initialized :\n",
    "            expt.initialize()\n",
    "        result = cls(expt.data, expt.comment + '\\n' + description, classifier, cdesc)\n",
    "        result.train_X, result.train_y = operation(expt.train_X, expt.train_y, 'train')\n",
    "        result.dev_X, result.dev_y = operation(expt.dev_X, expt.dev_y, 'dev')\n",
    "        result.test_X, result.test_y = operation(expt.test_X, expt.test_y, 'test')\n",
    "        result.initialized = True\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of Wang - Manning Weights\n",
    "\n",
    "[Based on ACL 2012 paper by Sida Wang and Chris Manning][1]\n",
    "\n",
    "[1]:http://aclweb.org/anthology/P/P12/P12-2018.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wang_manning_weights(expt) :\n",
    "    Xyes = expt.train_X[expt.train_y ==1, :]\n",
    "    Xno = expt.train_X[expt.train_y != 1, :] \n",
    "    yesrates = np.log((Xyes.getnnz(axis=0) + 1.) / Xyes.shape[1])\n",
    "    norates = np.log((Xno.getnnz(axis=0) + 1.) / Xno.shape[1])\n",
    "    W = scipy.sparse.diags(yesrates - norates, 0)\n",
    "    return lambda X, y, c: (X.dot(W), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Weight Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idf_weights(expt) :\n",
    "    idf = np.log((expt.train_X.shape[1] + 1.) / (expt.train_X.getnnz(axis=0) + 1.))\n",
    "    W = scipy.sparse.diags(idf, 0)\n",
    "    return lambda X, y, c: (X.dot(W), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include Glove Embeddings and SVD Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_embeddings(expt, embeddings, scale=True, stack=True) :\n",
    "    extra_features = expt.train_X.shape[1] - embeddings.shape[0]\n",
    "    if extra_features > 0 :\n",
    "        Z = scipy.sparse.csr_matrix((extra_features, embeddings.shape[1]))\n",
    "        W = scipy.sparse.vstack([embeddings, Z])\n",
    "    else: \n",
    "        W = embeddings\n",
    "    if scale :\n",
    "        scaler = StandardScaler(with_mean=False)\n",
    "        scaler.fit(expt.train_X.dot(W))\n",
    "    def operation(X, y, s) :\n",
    "        if scale:\n",
    "            new_features = scaler.transform(X.dot(W))\n",
    "        else :\n",
    "            new_features = X.dot(W)\n",
    "        if stack :\n",
    "            all_features = scipy.sparse.hstack([X, new_features]).tocsr()\n",
    "        else :\n",
    "            all_features = new_features\n",
    "        return (all_features, y)\n",
    "    return operation\n",
    "\n",
    "def dimensionality_reduction(expt, dimensions) :\n",
    "    _, _, wrt = scipy.sparse.linalg.svds(expt.train_X, k=dimensions, \n",
    "                                         return_singular_vectors='vh')\n",
    "    return add_embeddings(expt, np.transpose(wrt), stack=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include and Calculate bigram feature Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def use_bigram_features(data) :\n",
    "    f = vocabulary.Vocabulary.load(vocab_file, file_type=vocab_file_type)\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    word_fd = nltk.FreqDist(data.all_train_tokens())\n",
    "    bigram_fd = nltk.FreqDist(nltk.bigrams(data.all_train_tokens()))\n",
    "    finder = nltk.collocations.BigramCollocationFinder(word_fd, bigram_fd)\n",
    "    finder.apply_freq_filter(5)\n",
    "    pmi = finder.score_ngrams(bigram_measures.pmi)\n",
    "    collocations = [ (x,y) for x,y in pmi if y > 0 ]\n",
    "    for (w1, w2), _ in collocations:\n",
    "        f.add(w1 + \" \" + w2)\n",
    "    f.stop_growth()\n",
    "    return f\n",
    "\n",
    "def count_bigram_features(features, gen_tokens) :\n",
    "    prev = None\n",
    "    for t in gen_tokens :\n",
    "        r = features.add(t)\n",
    "        if r :\n",
    "            yield r\n",
    "            if prev :\n",
    "                r = features.add(prev + \" \" + t)\n",
    "                if r : \n",
    "                    yield r\n",
    "            prev = t\n",
    "            \n",
    "bigram_data = newsreader.DataManager(train_dir + class1,\n",
    "                                       train_dir + class2,\n",
    "                                       test_dir + class1,\n",
    "                                       test_dir + class2,\n",
    "                                       use_bigram_features,\n",
    "                                       make_boolean_features(count_bigram_features),\n",
    "                                       dev_dir + class1 if dev_dir else None,\n",
    "                                       dev_dir + class2 if dev_dir else None,\n",
    "                                       strip_metadata=has_bad_metadata)\n",
    "\n",
    "bigram_data.initialize(build_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning with only certain percentage of the total train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def limit_training(percent) :\n",
    "    def operation(X, y, s) :\n",
    "        if s != 'train' :\n",
    "            return (X, y)\n",
    "        data_to_take = int(X.shape[0] * percent)\n",
    "        indices = np.random.choice(X.shape[0], \n",
    "                                      size=data_to_take,\n",
    "                                      replace=False)\n",
    "        return (X[indices,:], y[indices])\n",
    "    return operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Number of Counts for Each Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "classified by logistic regression\n",
      "average accuracy 0.8772727272727273 (std 0.017647884050157735)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_10_\"):\n",
    "    expt_10_ = Experiment(count_data,\n",
    "                       \"{}: {} vs {}, using word count features\".format(all_data, class1, class2),\n",
    "                       sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                       \"logistic regression\")\n",
    "    expt_10_.initialize()\n",
    "    expt_10_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Booalean value - Presence/Absence for Each Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word presence/absence features\n",
      "classified by logistic regression\n",
      "average accuracy 0.9265151515151514 (std 0.010285561542634498)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_11_\") :\n",
    "    expt_11_ = Experiment(boolean_data,\n",
    "                         \"{}: {} vs {}, using word presence/absence features\".format(all_data, class1, class2),\n",
    "                         sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                         \"logistic regression\")\n",
    "    expt_11_.initialize()\n",
    "    expt_11_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with TF-IDF Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "features weighted by inverse document frequency\n",
      "classified by logistic regression\n",
      "average accuracy 0.8772727272727272 (std 0.01698502194020227)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_12_\") :\n",
    "    expt_12_ = Experiment.transform(expt_10_,\n",
    "                             idf_weights(expt_10_),\n",
    "                             \"features weighted by inverse document frequency\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                             \"logistic regression\")\n",
    "    expt_12_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Gram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word and bigram presence/absence features\n",
      "classified by logistic regression\n",
      "average accuracy 0.9247474747474748 (std 0.009569341071462834)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_13_\") :\n",
    "    expt_13_ = Experiment(bigram_data,\n",
    "                   \"{}: {} vs {}, using word and bigram presence/absence features\".format(all_data, class1, class2),\n",
    "                   sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                   \"logistic regression\")\n",
    "    expt_13_.initialize()\n",
    "    expt_13_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Counts + Wang - Manning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "features weighted by evidence they give of class\n",
      "classified by logistic regression\n",
      "average accuracy 0.9330808080808082 (std 0.011722721604479965)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_10_100_\") :\n",
    "    expt_10_100_ = Experiment.transform(expt_10_,\n",
    "                             wang_manning_weights(expt_10_),\n",
    "                             \"features weighted by evidence they give of class\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                             \"logistic regression\")\n",
    "    expt_10_100_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean (Presence/Absence) + Wang - Manning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word presence/absence features\n",
      "features weighted by evidence they give of class\n",
      "classified by logistic regression\n",
      "average accuracy 0.9436868686868685 (std 0.00559558580963644)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_11_101_\") :\n",
    "    expt_11_101_ = Experiment.transform(expt_11_,\n",
    "                             wang_manning_weights(expt_11_),\n",
    "                             \"features weighted by evidence they give of class\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                             \"logistic regression\")\n",
    "    expt_11_101_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + Wang - Manning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "features weighted by inverse document frequency\n",
      "features weighted by evidence they give of class\n",
      "classified by logistic regression\n",
      "average accuracy 0.9358585858585858 (std 0.015410248790295317)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_12_102_\") :\n",
    "    expt_12_102_ = Experiment.transform(expt_12_,\n",
    "                             wang_manning_weights(expt_12_),\n",
    "                             \"features weighted by evidence they give of class\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                             \"logistic regression\")\n",
    "    expt_12_102_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Gram + Wang - Manning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word and bigram presence/absence features\n",
      "features weighted by evidence they give of class\n",
      "classified by logistic regression\n",
      "average accuracy 0.9502525252525252 (std 0.004863979869762186)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_13_103_\") :\n",
    "    expt_13_103_ = Experiment.transform(expt_13_,\n",
    "                             wang_manning_weights(expt_13_),\n",
    "                             \"features weighted by evidence they give of class\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                             \"logistic regression\")\n",
    "    expt_13_103_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Counts + GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "enriched via word embeddings\n",
      "classified by logistic regression\n",
      "average accuracy 0.8722222222222221 (std 0.01447126139585293)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_10_200_\") :\n",
    "    expt_10_200_ = Experiment.transform(expt_10_,\n",
    "                             add_embeddings(expt_10_, e),\n",
    "                             \"enriched via word embeddings\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                            \"logistic regression\")\n",
    "    expt_10_200_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean (Presence/Absence) + GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word presence/absence features\n",
      "enriched via word embeddings\n",
      "classified by logistic regression\n",
      "average accuracy 0.9404040404040405 (std 0.011360830181012126)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_11_201_\") :\n",
    "    expt_11_201_ = Experiment.transform(expt_11_,\n",
    "                             add_embeddings(expt_11_, e),\n",
    "                             \"enriched via word embeddings\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                            \"logistic regression\")\n",
    "    expt_11_201_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "features weighted by inverse document frequency\n",
      "enriched via word embeddings\n",
      "classified by logistic regression\n",
      "average accuracy 0.8770202020202019 (std 0.020345136999554963)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_12_202_\") :\n",
    "    expt_12_202_ = Experiment.transform(expt_12_,\n",
    "                             add_embeddings(expt_12_, e),\n",
    "                             \"enriched via word embeddings\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                            \"logistic regression\")\n",
    "    expt_12_202_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Gram + GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word and bigram presence/absence features\n",
      "enriched via word embeddings\n",
      "classified by logistic regression\n",
      "average accuracy 0.9371212121212121 (std 0.008522493449841514)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_13_203_\") :\n",
    "    expt_13_203_ = Experiment.transform(expt_13_,\n",
    "                             add_embeddings(expt_13_, e),\n",
    "                             \"enriched via word embeddings\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                            \"logistic regression\")\n",
    "    expt_13_203_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Counts + LSA (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "transformed via LSA(100)\n",
      "classified by logistic regression\n",
      "average accuracy 0.9030303030303033 (std 0.008541179053175654)\n"
     ]
    }
   ],
   "source": [
    "if selected (\"expt_10_300_\") :\n",
    "    expt_10_300_ = Experiment.transform(expt_10_,\n",
    "                             dimensionality_reduction(expt_10_, 100),\n",
    "                             \"transformed via LSA(100)\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                           \"logistic regression\")\n",
    "    expt_10_300_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean (Presence/Absence) + LSA (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word presence/absence features\n",
      "transformed via LSA(100)\n",
      "classified by logistic regression\n",
      "average accuracy 0.9265151515151515 (std 0.0064825745722189064)\n"
     ]
    }
   ],
   "source": [
    "if selected (\"expt_11_301_\") :\n",
    "    expt_11_301_ = Experiment.transform(expt_11_,\n",
    "                             dimensionality_reduction(expt_11_, 100),\n",
    "                             \"transformed via LSA(100)\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                           \"logistic regression\")\n",
    "    expt_11_301_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + LSA (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "features weighted by inverse document frequency\n",
      "transformed via LSA(100)\n",
      "classified by logistic regression\n",
      "average accuracy 0.9098484848484848 (std 0.009619190381182268)\n"
     ]
    }
   ],
   "source": [
    "if selected (\"expt_12_302_\") :\n",
    "    expt_12_302_ = Experiment.transform(expt_12_,\n",
    "                             dimensionality_reduction(expt_12_, 100),\n",
    "                             \"transformed via LSA(100)\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                           \"logistic regression\")\n",
    "    expt_12_302_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Gram + LSA (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word and bigram presence/absence features\n",
      "transformed via LSA(100)\n",
      "classified by logistic regression\n",
      "average accuracy 0.9156565656565657 (std 0.005321037248915526)\n"
     ]
    }
   ],
   "source": [
    "if selected (\"expt_13_303_\") :\n",
    "    expt_13_303_ = Experiment.transform(expt_13_,\n",
    "                             dimensionality_reduction(expt_13_, 100),\n",
    "                             \"transformed via LSA(100)\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                           \"logistic regression\")\n",
    "    expt_13_303_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Counts + GloVe + LSA (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "enriched via word embeddings\n",
      "transformed via LSA(100)\n",
      "classified by logistic regression\n",
      "average accuracy 0.906060606060606 (std 0.00836007341275094)\n"
     ]
    }
   ],
   "source": [
    "if selected (\"expt_10_200_100_\") :\n",
    "    expt_10_200_100_ = Experiment.transform(expt_10_200_,\n",
    "                             dimensionality_reduction(expt_10_200_, 100),\n",
    "                             \"transformed via LSA(100)\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                           \"logistic regression\")\n",
    "    expt_10_200_100_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean (Presence/Absence) + GloVe + LSA (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word presence/absence features\n",
      "enriched via word embeddings\n",
      "transformed via LSA(100)\n",
      "classified by logistic regression\n",
      "average accuracy 0.9315656565656567 (std 0.00297722881882618)\n"
     ]
    }
   ],
   "source": [
    "if selected (\"expt_11_201_101_\") :\n",
    "    expt_11_201_101_ = Experiment.transform(expt_11_201_,\n",
    "                             dimensionality_reduction(expt_11_201_, 100),\n",
    "                             \"transformed via LSA(100)\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                           \"logistic regression\")\n",
    "    expt_11_201_101_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + GloVe + LSA (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "features weighted by inverse document frequency\n",
      "enriched via word embeddings\n",
      "transformed via LSA(100)\n",
      "classified by logistic regression\n",
      "average accuracy 0.9136363636363635 (std 0.009961152991573735)\n"
     ]
    }
   ],
   "source": [
    "if selected (\"expt_12_202_102_\") :\n",
    "    expt_12_202_102_ = Experiment.transform(expt_12_202_,\n",
    "                             dimensionality_reduction(expt_12_202_, 100),\n",
    "                             \"transformed via LSA(100)\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                           \"logistic regression\")\n",
    "    expt_12_202_102_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiGram + GloVe + LSA (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word and bigram presence/absence features\n",
      "enriched via word embeddings\n",
      "transformed via LSA(100)\n",
      "classified by logistic regression\n",
      "average accuracy 0.9234848484848485 (std 0.004000752403473432)\n"
     ]
    }
   ],
   "source": [
    "if selected (\"expt_13_203_103_\") :\n",
    "    expt_13_203_103_ = Experiment.transform(expt_13_203_,\n",
    "                             dimensionality_reduction(expt_13_203_, 100),\n",
    "                             \"transformed via LSA(100)\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                           \"logistic regression\")\n",
    "    expt_13_203_103_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Counts + GloVe + Wang - Manning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "enriched via word embeddings\n",
      "features weighted by evidence they give of class\n",
      "classified by logistic regression\n",
      "average accuracy 0.9237373737373739 (std 0.011394458760281294)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_10_200_200_\") :\n",
    "    expt_10_200_200_ = Experiment.transform(expt_10_200_,\n",
    "                             wang_manning_weights(expt_10_200_),\n",
    "                             \"features weighted by evidence they give of class\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                             \"logistic regression\")\n",
    "    expt_10_200_200_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean (Presence/Absence) + GloVe + Wang - Manning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word presence/absence features\n",
      "enriched via word embeddings\n",
      "features weighted by evidence they give of class\n",
      "classified by logistic regression\n",
      "average accuracy 0.9436868686868685 (std 0.004863979869762164)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_11_201_201_\") :\n",
    "    expt_11_201_201_ = Experiment.transform(expt_11_201_,\n",
    "                             wang_manning_weights(expt_11_201_),\n",
    "                             \"features weighted by evidence they give of class\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                             \"logistic regression\")\n",
    "    expt_11_201_201_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + GloVe + Wang - Manning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "features weighted by inverse document frequency\n",
      "enriched via word embeddings\n",
      "features weighted by evidence they give of class\n",
      "classified by logistic regression\n",
      "average accuracy 0.9308080808080808 (std 0.014293910806146363)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_12_202_202_\") :\n",
    "    expt_12_202_202_ = Experiment.transform(expt_12_202_,\n",
    "                             wang_manning_weights(expt_12_202_),\n",
    "                             \"features weighted by evidence they give of class\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                             \"logistic regression\")\n",
    "    expt_12_202_202_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiGram + GloVe + Wang - Manning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word and bigram presence/absence features\n",
      "enriched via word embeddings\n",
      "features weighted by evidence they give of class\n",
      "classified by logistic regression\n",
      "average accuracy 0.9477272727272726 (std 0.005362818328685694)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_13_203_203_\") :\n",
    "    expt_13_203_203_ = Experiment.transform(expt_13_203_,\n",
    "                             wang_manning_weights(expt_13_203_),\n",
    "                             \"features weighted by evidence they give of class\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                             \"logistic regression\")\n",
    "    expt_13_203_203_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Counts + x% of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "considering 10% training data\n",
      "classified by logistic regression\n",
      "average accuracy 0.781060606060606 (std 0.040633031647807745)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_10_400_\") :\n",
    "    expt_10_400_ = Experiment.transform(expt_10_,\n",
    "                             limit_training(0.1),\n",
    "                             \"considering 10% training data\",\n",
    "                            sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                            \"logistic regression\")\n",
    "    expt_10_400_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean (Presence/Abscence) + x% of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word presence/absence features\n",
      "considering 10% training data\n",
      "classified by logistic regression\n",
      "average accuracy 0.8803030303030303 (std 0.027896897938669653)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_11_401_\") :\n",
    "    expt_11_401_ = Experiment.transform(expt_11_,\n",
    "                             limit_training(0.1),\n",
    "                             \"considering 10% training data\",\n",
    "                            sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                            \"logistic regression\")\n",
    "    expt_11_401_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + x% of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "features weighted by inverse document frequency\n",
      "considering 10% training data\n",
      "classified by logistic regression\n",
      "average accuracy 0.709848484848485 (std 0.037129800422028326)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_12_402_\") :\n",
    "    expt_12_402_ = Experiment.transform(expt_12_,\n",
    "                             limit_training(0.1),\n",
    "                             \"considering 10% training data\",\n",
    "                            sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                            \"logistic regression\")\n",
    "    expt_12_402_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiGram + x% of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word and bigram presence/absence features\n",
      "considering 10% training data\n",
      "classified by logistic regression\n",
      "average accuracy 0.8699494949494951 (std 0.024372284760826392)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_13_403_\") :\n",
    "    expt_13_403_ = Experiment.transform(expt_13_,\n",
    "                             limit_training(0.1),\n",
    "                             \"considering 10% training data\",\n",
    "                            sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                            \"logistic regression\")\n",
    "    expt_13_403_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Counts  + x% of train data + Wang - Manning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "considering 10% training data\n",
      "features weighted by evidence they give of class\n",
      "classified by logistic regression\n",
      "average accuracy 0.8957070707070709 (std 0.024393207425703917)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_10_400_100_\") :\n",
    "    expt_10_400_100_ = Experiment.transform(expt_10_400_,\n",
    "                             wang_manning_weights(expt_10_400_),\n",
    "                             \"features weighted by evidence they give of class\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                             \"logistic regression\")\n",
    "    expt_10_400_100_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean (Presence/Absence)  + x% of train data + Wang - Manning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word presence/absence features\n",
      "considering 10% training data\n",
      "features weighted by evidence they give of class\n",
      "classified by logistic regression\n",
      "average accuracy 0.8984848484848487 (std 0.019091977950945246)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_11_401_101_\") :\n",
    "    expt_11_401_101_ = Experiment.transform(expt_11_401_,\n",
    "                             wang_manning_weights(expt_11_401_),\n",
    "                             \"features weighted by evidence they give of class\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                             \"logistic regression\")\n",
    "    expt_11_401_101_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + x% of train data + Wang - Manning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "features weighted by inverse document frequency\n",
      "considering 10% training data\n",
      "features weighted by evidence they give of class\n",
      "classified by logistic regression\n",
      "average accuracy 0.8767676767676769 (std 0.030193404399262883)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_12_402_102_\") :\n",
    "    expt_12_402_102_ = Experiment.transform(expt_12_402_,\n",
    "                             wang_manning_weights(expt_12_402_),\n",
    "                             \"features weighted by evidence they give of class\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                             \"logistic regression\")\n",
    "    expt_12_402_102_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Gram + x% of train data + Wang - Manning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word and bigram presence/absence features\n",
      "considering 10% training data\n",
      "features weighted by evidence they give of class\n",
      "classified by logistic regression\n",
      "average accuracy 0.8838383838383839 (std 0.02856997095703222)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_13_403_103_\") :\n",
    "    expt_13_403_103_ = Experiment.transform(expt_13_403_,\n",
    "                             wang_manning_weights(expt_13_403_),\n",
    "                             \"features weighted by evidence they give of class\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                             \"logistic regression\")\n",
    "    expt_13_403_103_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Counts + x% of train data + GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "considering 10% training data\n",
      "enriched via word embeddings\n",
      "classified by logistic regression\n",
      "average accuracy 0.8055555555555557 (std 0.0266530804079975)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_10_400_200_\") :\n",
    "    expt_10_400_200_ = Experiment.transform(expt_10_400_,\n",
    "                             add_embeddings(expt_10_400_, e),\n",
    "                             \"enriched via word embeddings\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                            \"logistic regression\")\n",
    "    expt_10_400_200_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean (Presence/Absence) + x% of train data + GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word presence/absence features\n",
      "considering 10% training data\n",
      "enriched via word embeddings\n",
      "classified by logistic regression\n",
      "average accuracy 0.9194444444444446 (std 0.012212931605397716)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_11_401_201_\") :\n",
    "    expt_11_401_201_ = Experiment.transform(expt_11_401_,\n",
    "                             add_embeddings(expt_11_401_, e),\n",
    "                             \"enriched via word embeddings\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                            \"logistic regression\")\n",
    "    expt_11_401_201_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + x% of train data + GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "features weighted by inverse document frequency\n",
      "considering 10% training data\n",
      "enriched via word embeddings\n",
      "classified by logistic regression\n",
      "average accuracy 0.7101010101010101 (std 0.03890528317691062)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_12_402_202_\") :\n",
    "    expt_12_402_202_ = Experiment.transform(expt_12_402_,\n",
    "                             add_embeddings(expt_12_402_, e),\n",
    "                             \"enriched via word embeddings\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                            \"logistic regression\")\n",
    "    expt_12_402_202_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Gram + x% of train data + GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word and bigram presence/absence features\n",
      "considering 10% training data\n",
      "enriched via word embeddings\n",
      "classified by logistic regression\n",
      "average accuracy 0.901767676767677 (std 0.022949252648457704)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_13_403_203_\") :\n",
    "    expt_13_403_203_ = Experiment.transform(expt_13_403_,\n",
    "                             add_embeddings(expt_13_403_, e),\n",
    "                             \"enriched via word embeddings\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                            \"logistic regression\")\n",
    "    expt_13_403_203_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Counts  + x% of train data + GloVe + Wang - Manning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "considering 10% training data\n",
      "enriched via word embeddings\n",
      "features weighted by evidence they give of class\n",
      "classified by logistic regression\n",
      "average accuracy 0.8866161616161617 (std 0.03065764729424961)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_10_400_100_100_\") :\n",
    "    expt_10_400_100_100_ = Experiment.transform(expt_10_400_200_,\n",
    "                             wang_manning_weights(expt_10_400_200_),\n",
    "                             \"features weighted by evidence they give of class\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                             \"logistic regression\")\n",
    "    expt_10_400_100_100_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean (Presence/Absence)  + x% of train data + GloVe + Wang - Manning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word presence/absence features\n",
      "considering 10% training data\n",
      "enriched via word embeddings\n",
      "features weighted by evidence they give of class\n",
      "classified by logistic regression\n",
      "average accuracy 0.9010101010101013 (std 0.020786985482077438)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_11_401_101_101_\") :\n",
    "    expt_11_401_101_101_ = Experiment.transform(expt_11_401_201_,\n",
    "                             wang_manning_weights(expt_11_401_201_),\n",
    "                             \"features weighted by evidence they give of class\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                             \"logistic regression\")\n",
    "    expt_11_401_101_101_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + x% of train data + GloVe + Wang - Manning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word count features\n",
      "features weighted by inverse document frequency\n",
      "considering 10% training data\n",
      "enriched via word embeddings\n",
      "features weighted by evidence they give of class\n",
      "classified by logistic regression\n",
      "average accuracy 0.8707070707070705 (std 0.023548572175504587)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_12_402_102_102_\") :\n",
    "    expt_12_402_102_102_ = Experiment.transform(expt_12_402_202_,\n",
    "                             wang_manning_weights(expt_12_402_202_),\n",
    "                             \"features weighted by evidence they give of class\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                             \"logistic regression\")\n",
    "    expt_12_402_102_102_.xval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Gram + x% of train data + GloVe + Wang - Manning Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-news-bydate: rec.sport.hockey vs comp.windows.x, using word and bigram presence/absence features\n",
      "considering 10% training data\n",
      "enriched via word embeddings\n",
      "features weighted by evidence they give of class\n",
      "classified by logistic regression\n",
      "average accuracy 0.8916666666666668 (std 0.024766793119504703)\n"
     ]
    }
   ],
   "source": [
    "if selected(\"expt_13_403_103_103_\") :\n",
    "    expt_13_403_103_103_ = Experiment.transform(expt_13_403_203_,\n",
    "                             wang_manning_weights(expt_13_403_203_),\n",
    "                             \"features weighted by evidence they give of class\",\n",
    "                             sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                       penalty=\"elasticnet\",\n",
    "                                       max_iter=50),\n",
    "                             \"logistic regression\")\n",
    "    expt_13_403_103_103_.xval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
